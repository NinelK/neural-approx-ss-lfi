{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import discrepancy, visualization\n",
    "from algorithms import ABC_algorithms, TPABC, SMCABC, SMC2ABC, SNLABC, SNL2ABC\n",
    "import distributions \n",
    "import scipy.stats as stats\n",
    "\n",
    "import utils_os, utils_math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.123"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(0.12345,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems.ABC_problems import ABC_Problem\n",
    "\n",
    "class Neuronal_Problem(ABC_Problem):\n",
    "    \n",
    "    def __init__(self, data, N=200, n=50):\n",
    "        \n",
    "        assert N <= data['Y'].shape[0]\n",
    "        assert data['Y'].ndim == 2\n",
    "        assert data['X'].shape[0] == data['Y'].shape[0]\n",
    "        \n",
    "        self.N = N # number of posterior samples\n",
    "#         subsample = np.random.choice(np.arange(data['Y'].shape[0]),size=N,replace=True)\n",
    "        self.n = n # length of the data vector x = {x_1, ..., x_n}\n",
    "        self.d = 1 # dimensionality of theta?\n",
    "        self.prior_args = np.repeat(np.array([-np.inf,np.inf]).reshape((1,-1)),self.N,axis=0) # surprisingly, these are bounds on theta (on X in our casee)\n",
    "        \n",
    "        self.all_thetas = data['X']#[subsample]\n",
    "        self.y_obs = data['Y']#[subsample]\n",
    "        self.sim_accuracy = 4 # number of digits after a decimal point for theta\n",
    "        self.sim = {np.round(data['X'][i],self.sim_accuracy): data['Y'][i] for i in range(data['X'].shape[0])} #here we use all!\n",
    "        self.K = self.N # dimensionality of summary statistics???\n",
    "        self.stat = 'raw' # raw means that sufficient statistics is unknown (I guess). y_obs = data_obs\n",
    "        \n",
    "        self.data_obs = self.y_obs #important that first dim=N & y_dim = product of these dims\n",
    "    \n",
    "    def get_true_theta(self):\n",
    "        pass\n",
    "\n",
    "    def sample_from_prior(self):\n",
    "        return np.random.choice(self.all_thetas,size=self.N,replace=True) # just 1 sample, but may be a vector!!!!\n",
    "    \n",
    "    def simulator(self, theta):\n",
    "        # instead of using the best nearest neighbour, use the best from a subsample FIX LATER\n",
    "        y = np.empty((len(theta),self.y_obs.shape[1]))\n",
    "        for i,t_raw in enumerate(theta):\n",
    "            t = np.round(t_raw,self.sim_accuracy)\n",
    "            if t in self.sim:\n",
    "                y[i] = self.sim[t]\n",
    "            else:\n",
    "                subsample = np.random.choice(np.arange(self.all_thetas.shape[0]),size=self.N,replace=True)\n",
    "                print('Subsampling for simulating new thetas!!!')\n",
    "                discr = np.abs(self.all_thetas[subsample] - t)\n",
    "                y[i] = self.sim[self.all_thetas[subsample][np.argmin(discr)]]\n",
    "        return y # self.n x thetas (which is 1 o_O )\n",
    "\n",
    "    # B. correlation between latent\n",
    "    def _ss_corr(self, Z):\n",
    "        V = np.mat(Z).T * np.mat(Z) / Z.shape[0]\n",
    "        (d,d) = V.shape\n",
    "        upper_tri_elements = V[np.triu_indices(d, k=1)]\n",
    "        stat = np.array(upper_tri_elements)\n",
    "        return stat\n",
    "    \n",
    "    def statistics(self, data, theta=None):\n",
    "        if self.stat == 'raw':\n",
    "            # (correlation) as summary statistics (NO MARGINALS in these data)\n",
    "            stat = self._ss_corr(data)\n",
    "            return stat\n",
    "        else:\n",
    "            raise NotImplementedError('No ground truth statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21471, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "with open(f'/home/nina/CopulaGP/plos_fig5_data/ST260_Day1_Dataset.pkl',\"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "    \n",
    "data['Y'] = data['Y'][:,:10]\n",
    "print(data['Y'].shape)\n",
    "    \n",
    "problem = Neuronal_Problem(data)\n",
    "\n",
    "DIR = 'results/Neuronal' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nn import ISN, MSN, MAF, MDN\n",
    "\n",
    "# def fit_vae(s):\n",
    "#     print('\\n > fitting encoder')\n",
    "#     all_stats = torch.tensor(np.vstack(s.all_stats[0:s.l+1])).float().to(s.device)\n",
    "#     all_samples = torch.tensor(np.vstack(s.all_samples[0:s.l+1])).float().to(s.device)\n",
    "#     print(all_stats.shape,all_samples.shape,s.hidden_ratio)\n",
    "#     [n, dim] = all_stats.size()\n",
    "#     h = int(dim*s.hidden_ratio)\n",
    "#     print('summary statistic dim =', h, 'original dim =', dim)\n",
    "#     architecture = [dim] + [100, 100, h]    \n",
    "#     print('architecture', architecture)\n",
    "#     net = ISN.ISN(architecture, dim_y=s.problem.K, hyperparams=s.msn_hyperparams)\n",
    "#     net.train().to(s.device)\n",
    "#     net.learn(x=all_stats, y=all_samples)\n",
    "#     net = net.eval().cpu()\n",
    "#     s.vae_net = net\n",
    "#     s.vae_array.append(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class data_SNL2(SNL2ABC.SNL2_ABC):\n",
    "#     def __init__(self, problem, discrepancy, hyperparams, **kwargs):\n",
    "#         super(data_SNL2, self).__init__(problem, discrepancy, hyperparams, **kwargs)\n",
    "        \n",
    "#         self.needed_hyperparams = ['epsilon']\n",
    "#         self.epsilon = hyperparams.epsilon\n",
    "#         self.device = torch.device(hyperparams.device)\n",
    "#         self.nde_net = None                             # the learned q(x|theta)\n",
    "#         self.vae_net = None                             # the learned s(x)\n",
    "#         self.nde_array = []                             \n",
    "#         self.vae_array = []     \n",
    "#         self.proposal_array = []                        # the proposal used at each round\n",
    "#         self.hidden_ratio = hyperparams.hidden_ratio    # dimensionality of s.s \n",
    "#         self.msn_hyperparams = hyperparams\n",
    "#         self.msn_hyperparams.y_obs = self.convert_stat(self.whiten(self.y_obs))\n",
    "    \n",
    "#     def simulate(self):\n",
    "\n",
    "#         # > wrapper function of rejection sampling algorithm. Launch several processes to do sampling in parallel\n",
    "\n",
    "#         # Initialization\n",
    "#         self.stats = np.zeros((self.num_sim, self.y_dim), float)\n",
    "#         self.samples = np.zeros((self.num_sim, self.num_theta), float)\n",
    "#         self.discrepancies = []\n",
    "        \n",
    "#         for i in range(self.num_sim):\n",
    "#             theta = self.prior()\n",
    "#             y = self.problem.simulator(theta).reshape(-1)\n",
    "#             self.samples[i] = theta\n",
    "#             self.stats[i] = y\n",
    "#             # Calculate error\n",
    "#             error = self.discrepancy(self.y_obs, y)\n",
    "#             self.discrepancies.append(error) # does it matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential Neural Likelihood + \n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:0'\n",
    "hyperparams.num_sim = 1000                        # number of simulations # original can't be <1000 LOL.. bugs!\n",
    "hyperparams.L = 10                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.05                  # dimensionality of S(x)\n",
    "hyperparams.type = 'plain'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'JSD'                    # MI estimator; JSD or DC, see the paper\n",
    "hyperparams.nde = 'MAF'                          # nde; MAF (D>1) or MDN (D=1)\n",
    "\n",
    "snl2_abc = SNL2ABC.SNL2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "\n",
    "# JSD_array = []\n",
    "# for l in range(len(snl2_abc.nde_array)):\n",
    "#     print('l=', l)\n",
    "#     snl2_abc.set(l=l)\n",
    "#     visualization.plot_likelihood(samples=true_samples, log_likelihood_function=snl2_abc.log_likelihood, dimensions=(0,1))\n",
    "#     JSD = discrepancy.JSD(snl2_abc.log_likelihood, snl2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "#     JSD_array.append(JSD)\n",
    "#     print('JSD snl+ = ', JSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start![ABC] sub-process start!\n",
      "\n",
      "[sampling] finished sampling  [ABC] sub-process start!\n",
      "5[ABC] sub-process start!\n",
      "\n",
      "[sampling] finished sampling  10\n",
      "[sampling] finished sampling  15\n",
      "[sampling] finished sampling  20\n",
      "\n",
      " > fitting encoder\n",
      "summary statistic dim = 2 original dim = 45\n",
      "architecture [45, 100, 100, 2]\n",
      "validation size= 0.8\n",
      "finished: t= 0 loss= 1.386307716369629 loss val= 1.3863115310668945 time= 0.07755160331726074\n",
      "finished: t= 50 loss= 1.3862273693084717 loss val= 1.386296272277832 time= 0.039060354232788086\n",
      "finished: t= 100 loss= 1.3859100341796875 loss val= 1.3862812519073486 time= 0.038402557373046875\n",
      "finished: t= 150 loss= 1.3847376108169556 loss val= 1.3863153457641602 time= 0.03786921501159668\n",
      "finished: t= 200 loss= 1.3820996284484863 loss val= 1.3861336708068848 time= 0.04541611671447754\n",
      "finished: t= 250 loss= 1.3746299743652344 loss val= 1.3855609893798828 time= 0.041015625\n",
      "finished: t= 300 loss= 1.3489980697631836 loss val= 1.3847110271453857 time= 0.05712628364562988\n",
      "finished: t= 350 loss= 1.3019988536834717 loss val= 1.385380744934082 time= 0.04120182991027832\n",
      "finished: t= 400 loss= 1.2490551471710205 loss val= 1.396771788597107 time= 0.038637638092041016\n",
      "finished: t= 450 loss= 1.1983132362365723 loss val= 1.420762300491333 time= 0.08446621894836426\n",
      "best val loss= 1.384007215499878\n",
      "\n",
      " > fitting nde\n",
      "all_stats.size() torch.Size([100, 2])\n",
      "finished: t= 0 loss= 20.863554000854492 loss val= 12.723597526550293\n",
      "best val loss= -1.719106912612915\n",
      "\n",
      " > fitting proposal\n",
      "mu= [[0.61020505 0.59121491 0.55807639 0.6231312  0.58450902 0.5853548\n",
      "  0.60536593 0.55969236 0.57499605 0.5260824  0.59666241 0.58509953\n",
      "  0.59817962 0.60303146 0.57684641 0.56709236 0.59162273 0.56919548\n",
      "  0.58902112 0.59988076 0.59339898 0.58391472 0.62547828 0.58895857\n",
      "  0.5698217  0.59388186 0.57440408 0.60135189 0.60520841 0.61792962\n",
      "  0.61808422 0.57863396 0.58731723 0.58405594 0.60436151 0.60419452\n",
      "  0.55776524 0.60125184 0.59485407 0.57823122 0.56474075 0.6257159\n",
      "  0.58105516 0.5586042  0.5585204  0.58844408 0.54407096 0.5516824\n",
      "  0.59792259 0.56243288 0.59449781 0.59236261 0.58907743 0.60150332\n",
      "  0.61925438 0.51922216 0.5603128  0.57896057 0.5466153  0.59844832\n",
      "  0.58202348 0.57298812 0.59437634 0.57016235 0.56064292 0.60290531\n",
      "  0.54001015 0.58017663 0.60218314 0.61229134 0.5436198  0.60571621\n",
      "  0.57365965 0.60076142 0.58665923 0.56449597 0.54228026 0.59680914\n",
      "  0.56544078 0.52399439 0.59976189 0.59717316 0.57002998 0.58275454\n",
      "  0.57643398 0.60897234 0.59857342 0.58101539 0.59839807 0.62116403\n",
      "  0.55276829 0.59738471 0.57852599 0.58197207 0.58823024 0.58233424\n",
      "  0.59214519 0.57188155 0.58379252 0.61833369 0.55082679 0.55127764\n",
      "  0.60272692 0.575486   0.56891972 0.56257876 0.60285531 0.60269868\n",
      "  0.55375348 0.56774043 0.61945742 0.60314318 0.58832075 0.65699318\n",
      "  0.57542742 0.61322881 0.59970889 0.57323912 0.58669365 0.54209162\n",
      "  0.58543536 0.55069339 0.57336231 0.57971028 0.56449604 0.63472977\n",
      "  0.57669841 0.58562308 0.56138312 0.57764318 0.59957005 0.56301571\n",
      "  0.57703405 0.64351278 0.58057495 0.55601794 0.57589943 0.57227619\n",
      "  0.61346314 0.59097957 0.57969421 0.56997455 0.62881247 0.59567423\n",
      "  0.61610231 0.53301511 0.57904083 0.6092292  0.59158    0.62225833\n",
      "  0.59321642 0.60567307 0.5946973  0.5527526  0.63750488 0.6241493\n",
      "  0.56751199 0.59615238 0.58311291 0.57441917 0.58361553 0.56521467\n",
      "  0.61903937 0.59567905 0.58364246 0.58450127 0.58206899 0.61074062\n",
      "  0.59886056 0.5958299  0.57641245 0.54397076 0.56973921 0.59528197\n",
      "  0.62185433 0.58746661 0.58010839 0.55864337 0.56458115 0.5658055\n",
      "  0.55812814 0.64962973 0.58893528 0.56377254 0.5626982  0.61096107\n",
      "  0.58017652 0.56970952 0.56339737 0.57302251 0.5079715  0.60594885\n",
      "  0.57909256 0.58320638 0.58901211 0.56669549 0.55260641 0.5882489\n",
      "  0.59555735 0.63331729]]\n",
      "cov= [[ 0.08038055  0.00694562 -0.00232169 ... -0.01232847  0.00696412\n",
      "   0.00866517]\n",
      " [ 0.00694562  0.08535691  0.00264366 ... -0.00573639 -0.00884567\n",
      "   0.00320241]\n",
      " [-0.00232169  0.00264366  0.09293332 ... -0.00700914 -0.00555885\n",
      "  -0.00233178]\n",
      " ...\n",
      " [-0.01232847 -0.00573639 -0.00700914 ...  0.08024131 -0.00915507\n",
      "  -0.00249179]\n",
      " [ 0.00696412 -0.00884567 -0.00555885 ... -0.00915507  0.08650537\n",
      "  -0.00279056]\n",
      " [ 0.00866517  0.00320241 -0.00233178 ... -0.00249179 -0.00279056\n",
      "   0.07689452]]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cholesky_cpu: U(200,200) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b6443f04028a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnl2_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neural-approx-ss-lfi/algorithms/SNL2ABC.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_nde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_proposal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/algorithms/SNL2ABC.py\u001b[0m in \u001b[0;36mlearn_proposal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mgaussian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgaussian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_tril\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcovariance_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# precision_matrix is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_precision_to_scale_tril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cholesky_cpu: U(200,200) is zero, singular U."
     ]
    }
   ],
   "source": [
    "snl2_abc.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snl2_abs.convert_stat(data['Y']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = torch.tensor(np.vstack(snl2_abc.all_stats[0:snl2_abc.l+1])).float()\n",
    "all_samples = torch.tensor(np.vstack(snl2_abc.all_samples[0:snl2_abc.l+1])).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.MI(all_stats,all_samples,n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(snl2_abc.all_samples[0:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21471, 10])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (21471x10 and 100x100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-3793cf240d68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msnl2_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/ISN.py\u001b[0m in \u001b[0;36mencode2\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# theta = h(y), get the representation of y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode2_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/ISN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfront_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/ISN.py\u001b[0m in \u001b[0;36mfront_end\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plain'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (21471x10 and 100x100)"
     ]
    }
   ],
   "source": [
    "all_samples = torch.tensor(data['Y']).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.encode2(all_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMC-ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-22:\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sequential Monte Carlo ABC\n",
    "\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:0'\n",
    "hyperparams.num_sim = 4000                        # number of simulations\n",
    "hyperparams.num_samples = 150                     # number of samples to represent posterior\n",
    "hyperparams.L = 2                                 # number of rounds in sequential learning\n",
    "\n",
    "smc_abc = SMCABC.SMC_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "smc_abc.run()\n",
    "\n",
    "JSD_smc_array = []\n",
    "for l in range(hyperparams.L):\n",
    "    print('round =', l)\n",
    "    smc_abc.posterior = smc_abc.posterior_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=smc_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, smc_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_smc_array.append(JSD)\n",
    "    print('JSD smc = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SMC', JSD_smc_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Monte Carlo ABC +\n",
    "\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 2000                       # number of simulations\n",
    "hyperparams.num_samples = 150                    # number of samples to represent posterior\n",
    "hyperparams.L = 10                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.05                  # dimensionality of S(x)\n",
    "hyperparams.type = 'cnn2d'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'JSD'                    # MI estimator; JSD or DC, see the paper\n",
    "\n",
    "smc2_abc = SMC2ABC.SMC2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "smc2_abc.run()\n",
    "\n",
    "JSD_smc2_array = []\n",
    "for l in range(len(smc2_abc.posterior_array)):\n",
    "    print('l=', l)\n",
    "    smc2_abc.l = l\n",
    "    smc2_abc.posterior = smc2_abc.posterior_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=smc2_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, smc2_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_smc2_array.append(JSD)\n",
    "    print('JSD smc2 = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SMC2', JSD_smc2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sequential Neural Likelihood\n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:1'\n",
    "hyperparams.num_sim = 1000\n",
    "hyperparams.L = 10\n",
    "\n",
    "print('\\n SNL ABC')\n",
    "snl_abc = SNLABC.SNL_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n",
    "snl_abc.run()\n",
    "\n",
    "JSD_array = []\n",
    "for l in range(len(snl_abc.nde_array)):\n",
    "    print('l=', l)\n",
    "    snl_abc.nde_net = snl_abc.nde_array[l]\n",
    "    visualization.plot_likelihood(samples=true_samples, log_likelihood_function=snl_abc.log_likelihood, dimensions=(0,1))\n",
    "    JSD = discrepancy.JSD(tp_abc.log_likelihood, snl_abc.log_likelihood, true_samples, true_samples, N_grid=30)\n",
    "    JSD_array.append(JSD)\n",
    "    print('JSD snl = ', JSD)\n",
    "utils_os.save_object(DIR, 'JSD_SNL', JSD_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
