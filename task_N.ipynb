{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import discrepancy, visualization\n",
    "from algorithms import ABC_algorithms, TPABC, SMCABC, SMC2ABC, SNLABC, SNL2ABC\n",
    "import distributions \n",
    "import scipy.stats as stats\n",
    "\n",
    "import utils_os, utils_math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems.ABC_problems import ABC_Problem\n",
    "\n",
    "class Neuronal_Problem(ABC_Problem):\n",
    "    \n",
    "    def __init__(self, data, N=100, n=50):\n",
    "        \n",
    "        assert N <= data['Y'].shape[0]\n",
    "        assert data['Y'].ndim == 2\n",
    "        assert data['X'].shape[0] == data['Y'].shape[0]\n",
    "        \n",
    "        self.N = N # number of posterior samples\n",
    "        self.n = n # length of the data vector x = {x_1, ..., x_n}\n",
    "#         self.d = 5 # dims of sufficient statistics? d=2K? This argument is just not used anywhere... great\n",
    "        self.prior_args = np.array([0,1]) # these are bounds on theta (on X in our case: [0,1])\n",
    "        \n",
    "        self.all_thetas = data['X']\n",
    "        self.y_obs = data['Y']\n",
    "        self.sim_accuracy = 4 # number of digits after a decimal point for theta\n",
    "        self.sim = {np.round(data['X'][i],self.sim_accuracy): data['Y'][i] for i in range(data['X'].shape[0])} #here we use all!\n",
    "        self.K = 1 # number of thetas\n",
    "        self.stat = 'raw' # raw means that sufficient statistics is unknown (I guess). y_obs = data_obs\n",
    "        \n",
    "        self.data_obs = self.y_obs #important that first dim=N & y_dim = product of these dims\n",
    "        \n",
    "        self.is_batch_sampling_supported = False # (unfinished feature, so keep False for now) speed up rejection sampling\n",
    "    \n",
    "    def get_true_theta(self):\n",
    "        pass # does not matter, as the result goes into 'statistics', where theta is currently not used\n",
    "\n",
    "    def sample_from_prior(self, size=1):\n",
    "        return np.random.choice(self.all_thetas,size=size,replace=True) # just 1 sample, but may be a vector!!!!\n",
    "    \n",
    "    def simulator(self, theta):\n",
    "        # instead of using the best nearest neighbour, use the best from a subsample FIX LATER\n",
    "        y = np.empty((len(theta),self.y_obs.shape[1]))\n",
    "        for i,t_raw in enumerate(theta):\n",
    "            t = np.round(t_raw,self.sim_accuracy)\n",
    "            if t in self.sim:\n",
    "                y[i] = self.sim[t]\n",
    "            else: # this part is used for newly-generated samples; let's take the Y=Y(closest X).\n",
    "                discr = np.abs(self.all_thetas - t) # get distances\n",
    "                y[i] = self.sim[np.round(self.all_thetas[np.argmin(discr)],self.sim_accuracy)] # take the closest\n",
    "        return y # self.n x thetas (which is 1 o_O )\n",
    "\n",
    "    # B. correlation between latent\n",
    "    def _ss_corr(self, Z):\n",
    "        V = np.mat(Z).T * np.mat(Z) / Z.shape[0]\n",
    "        (d,d) = V.shape\n",
    "        upper_tri_elements = V[np.triu_indices(d, k=1)]\n",
    "        stat = np.array(upper_tri_elements)\n",
    "        return stat\n",
    "    \n",
    "    def statistics(self, data, theta=None):\n",
    "        if self.stat == 'raw':\n",
    "            # (correlation) as summary statistics (NO MARGINALS in these data)\n",
    "            stat = self._ss_corr(data)\n",
    "            return stat\n",
    "        else:\n",
    "            raise NotImplementedError('No ground truth statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21471, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "with open(f'/home/nina/CopulaGP/plos_fig5_data/ST260_Day1_Dataset.pkl',\"rb\") as f:\n",
    "    data = pkl.load(f)\n",
    "    \n",
    "data['Y'] = data['Y'][:,:10] # taking the first N variables here (use second index)\n",
    "print(data['Y'].shape) # samples x neuronal/behavioral variables\n",
    "    \n",
    "problem = Neuronal_Problem(data)\n",
    "\n",
    "DIR = 'results/Neuronal' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential Neural Likelihood + \n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:0'\n",
    "hyperparams.num_sim = 1000                        # number of simulations\n",
    "hyperparams.L = 5                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.1                   # dimensionality of S(x)\n",
    "hyperparams.type = 'plain'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'NWJ'                    # MI estimator; JSD or DC, see the paper\n",
    "hyperparams.nde = 'MDN'                          # nde; MAF (D>1) or MDN (D=1)\n",
    "\n",
    "snl2_abc = SNL2ABC.SNL2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start!\n",
      "[sampling] finished sampling  10\n",
      "[sampling] finished sampling  20\n",
      "[sampling] finished sampling  30\n",
      "[sampling] finished sampling  40\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "\n",
      " > fitting encoder\n",
      "summary statistic dim = 4 original dim = 45\n",
      "architecture [45, 100, 100, 4]\n",
      "validation size= 0.8\n",
      "finished: t= 0 loss= 0.2979995906352997 loss val= 0.29321515560150146 time= 0.11103296279907227\n",
      "finished: t= 50 loss= 0.08466088771820068 loss val= 0.07968932390213013 time= 0.08026671409606934\n",
      "finished: t= 100 loss= 0.008992254734039307 loss val= 0.008963286876678467 time= 0.09358429908752441\n",
      "finished: t= 150 loss= 0.003239750862121582 loss val= 0.0031341910362243652 time= 0.10678577423095703\n",
      "finished: t= 200 loss= 0.0008211731910705566 loss val= 0.0007680058479309082 time= 0.12104392051696777\n",
      "finished: t= 250 loss= 0.00013583898544311523 loss val= 0.00014454126358032227 time= 0.11028313636779785\n",
      "finished: t= 300 loss= 4.2378902435302734e-05 loss val= 6.091594696044922e-05 time= 0.106353759765625\n",
      "finished: t= 350 loss= 1.9550323486328125e-05 loss val= 4.8041343688964844e-05 time= 0.10821795463562012\n",
      "finished: t= 400 loss= 8.702278137207031e-06 loss val= 3.421306610107422e-05 time= 0.10787343978881836\n",
      "finished: t= 450 loss= 2.7418136596679688e-06 loss val= 2.7179718017578125e-05 time= 0.05426335334777832\n",
      "finished: t= 500 loss= -2.205371856689453e-06 loss val= 2.372264862060547e-05 time= 0.08095622062683105\n",
      "finished: t= 550 loss= -6.854534149169922e-06 loss val= 2.0623207092285156e-05 time= 0.10805058479309082\n",
      "finished: t= 600 loss= -1.3172626495361328e-05 loss val= 1.9311904907226562e-05 time= 0.08015632629394531\n",
      "finished: t= 650 loss= -1.811981201171875e-05 loss val= 1.800060272216797e-05 time= 0.10590100288391113\n",
      "finished: t= 700 loss= -2.658367156982422e-05 loss val= 2.7298927307128906e-05 time= 0.07295346260070801\n",
      "finished: t= 750 loss= -3.707408905029297e-05 loss val= 3.039836883544922e-05 time= 0.10858774185180664\n",
      "finished: t= 800 loss= -4.8160552978515625e-05 loss val= 3.993511199951172e-05 time= 0.10834717750549316\n",
      "best val loss= 1.609325408935547e-05\n",
      "\n",
      " > fitting nde\n",
      "all_stats.size() torch.Size([200, 4])\n",
      "finished: t= 0 loss= 3.538719654083252 loss val= 3.517188310623169\n",
      "finished: t= 250 loss= -9.425951957702637 loss val= -9.109809875488281\n",
      "finished: t= 500 loss= -9.781645774841309 loss val= -9.321942329406738\n",
      "best val loss= -9.573135375976562\n",
      "\n",
      " > fitting proposal\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "mu= [[0.59842719]]\n",
      "cov= [[0.10798824]]\n",
      "\n",
      "\n",
      "iteration  1\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start!\n",
      "[sampling] finished sampling  10\n",
      "[sampling] finished sampling  20\n",
      "[sampling] finished sampling  30\n",
      "[sampling] finished sampling  40\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "[ABC] sub-process start!\n",
      "\n",
      " > fitting encoder\n",
      "summary statistic dim = 4 original dim = 45\n",
      "architecture [45, 100, 100, 4]\n",
      "validation size= 0.8\n",
      "finished: t= 0 loss= 0.35840728878974915 loss val= 0.354423463344574 time= 0.2368154525756836\n",
      "finished: t= 50 loss= 0.14384382963180542 loss val= 0.13743111491203308 time= 0.15706491470336914\n",
      "finished: t= 100 loss= 0.00587010383605957 loss val= 0.006786823272705078 time= 0.22102141380310059\n",
      "finished: t= 150 loss= 0.0015279650688171387 loss val= 0.0017260909080505371 time= 0.22209548950195312\n",
      "finished: t= 200 loss= 0.0005859136581420898 loss val= 0.0006808638572692871 time= 0.19994807243347168\n",
      "finished: t= 250 loss= 0.00014823675155639648 loss val= 0.0001806020736694336 time= 0.21573472023010254\n",
      "finished: t= 300 loss= 3.445148468017578e-05 loss val= 9.071826934814453e-05 time= 0.14568614959716797\n",
      "finished: t= 350 loss= -2.0325183868408203e-05 loss val= 3.7789344787597656e-05 time= 0.1893601417541504\n",
      "finished: t= 400 loss= -5.1021575927734375e-05 loss val= 7.152557373046875e-06 time= 0.2113504409790039\n",
      "finished: t= 450 loss= -7.408857345581055e-05 loss val= -1.0728836059570312e-06 time= 0.21405935287475586\n",
      "finished: t= 500 loss= -8.857250213623047e-05 loss val= -1.6808509826660156e-05 time= 0.22089910507202148\n",
      "finished: t= 550 loss= -0.00010019540786743164 loss val= -1.9073486328125e-05 time= 0.1994490623474121\n",
      "finished: t= 600 loss= -0.00011157989501953125 loss val= -2.6464462280273438e-05 time= 0.10527491569519043\n",
      "finished: t= 650 loss= -0.00012224912643432617 loss val= -2.7179718017578125e-05 time= 0.22511744499206543\n",
      "finished: t= 700 loss= -0.00012475252151489258 loss val= -3.0994415283203125e-05 time= 0.22535252571105957\n",
      "finished: t= 750 loss= -0.00013321638107299805 loss val= -3.24249267578125e-05 time= 0.2207639217376709\n",
      "finished: t= 800 loss= -0.0001525282859802246 loss val= -4.57763671875e-05 time= 0.20656514167785645\n",
      "finished: t= 850 loss= -0.0001652240753173828 loss val= -5.5670738220214844e-05 time= 0.16267871856689453\n",
      "finished: t= 900 loss= -0.0001894831657409668 loss val= -6.866455078125e-05 time= 0.15270519256591797\n",
      "finished: t= 950 loss= -0.0001919269561767578 loss val= -6.127357482910156e-05 time= 0.16035938262939453\n",
      "finished: t= 1000 loss= -0.0002251267433166504 loss val= -3.7670135498046875e-05 time= 0.21279096603393555\n",
      "finished: t= 1050 loss= -0.00023931264877319336 loss val= -8.58306884765625e-05 time= 0.1531374454498291\n",
      "finished: t= 1100 loss= -0.00026917457580566406 loss val= -0.00010502338409423828 time= 0.20389580726623535\n",
      "finished: t= 1150 loss= -0.00030857324600219727 loss val= -0.00010669231414794922 time= 0.15413403511047363\n",
      "finished: t= 1200 loss= -0.0003387928009033203 loss val= -0.00010657310485839844 time= 0.16507840156555176\n",
      "finished: t= 1250 loss= -0.0003935694694519043 loss val= -0.00012481212615966797 time= 0.14781832695007324\n"
     ]
    }
   ],
   "source": [
    "snl2_abc.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = snl2_abc.problem.sample_from_prior(size=20000)\n",
    "# net = snl2_abc.nde_net\n",
    "# y_obs, theta = snl2_abc.convert_stat(snl2_abc.whiten(snl2_abc.y_obs)), theta\n",
    "# # y_obs = np.repeat(y_obs,400,axis=0)\n",
    "# print(y_obs.shape)\n",
    "# y_obs, theta = torch.tensor(y_obs).float(), torch.tensor(theta).float().view(1, -1)\n",
    "# log_probs = net.log_probs(inputs=y_obs, cond_inputs=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  16.,  50., 132., 217., 225., 210., 100.,  37.,  10.]),\n",
       " array([0.12671691, 0.23752056, 0.3483242 , 0.45912785, 0.5699315 ,\n",
       "        0.68073514, 0.79153879, 0.90234243, 1.01314608, 1.12394972,\n",
       "        1.23475337]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff389b000f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us check that the prior did not collapse \n",
    "theta = np.empty(1000)\n",
    "for i in range(len(theta)): \n",
    "    theta[i] = snl2_abc.prior()\n",
    "plt.xlim([0,1])\n",
    "plt.hist(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04942602, -0.03361893,  0.00481226]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get latents s(x)\n",
    "snl2_abc.convert_stat(snl2_abc.problem.statistics(data['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9385, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate MI using all generated subsamples\n",
    "all_stats = torch.tensor(np.vstack(snl2_abc.all_stats[0:snl2_abc.l+1])).float()\n",
    "all_samples = torch.tensor(np.vstack(snl2_abc.all_samples[0:snl2_abc.l+1])).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.MI(all_stats,all_samples,n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9385, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate MI using all recordings\n",
    "stats = torch.tensor(snl2_abc.problem.statistics(data['Y'])).float()\n",
    "samples = torch.tensor(data['X']).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.MI(all_stats,all_samples,n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
