{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect, time\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "import discrepancy, visualization\n",
    "from algorithms import ABC_algorithms, TPABC, SMCABC, SMC2ABC, SNLABC, SNL2ABC\n",
    "import distributions \n",
    "import scipy.stats as stats\n",
    "\n",
    "import utils_os, utils_math\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problems.ABC_problems import ABC_Problem\n",
    "\n",
    "class Gauss_Problem(ABC_Problem): #problem from Fig.4A in PLoS CB Copula paper\n",
    "    \n",
    "    def __init__(self, N=100, n=100):\n",
    "        \n",
    "        self.N = N # number of posterior samples\n",
    "        self.n = n # length of the data vector x = {x_1, ..., x_n}\n",
    "        self.D = 5 # dimensionality of data samples\n",
    "#         self.d = 5 # dims of sufficient statistics? d=2K? This argument is just not used anywhere... great\n",
    "        self.prior_args = np.array([[0,1]]) # these are bounds on theta (on X in our case: [0,1])\n",
    "        \n",
    "        self.K = 1 # number of thetas\n",
    "        self.stat = 'raw' # raw means that sufficient statistics is unknown (I guess). y_obs = data_obs\n",
    "        \n",
    "#         self.data_obs = self.y_obs #important that first dim=N & y_dim = product of these dims\n",
    "        \n",
    "        self.is_batch_sampling_supported = False # (unfinished feature, so keep False for now) speed up rejection sampling\n",
    "    \n",
    "    def get_true_theta(self):\n",
    "        pass # does not matter, as the result goes into 'statistics', where theta is currently not used\n",
    "\n",
    "    def sample_from_prior(self,size=1):\n",
    "        return np.random.rand(size)\n",
    "    \n",
    "    def simulator(self, theta):\n",
    "        rho = -0.1 + (0.999+0.1)*theta #problem from Fig.4A in PLoS CB Copula paper, linearly changing rho\n",
    "        samples = np.zeros((theta.size,self.n,self.D))\n",
    "        for i,r in enumerate(rho):\n",
    "            samples[i] = np.random.multivariate_normal(np.zeros(self.D),np.ones((self.D,self.D))*r +\\\n",
    "                                                np.eye(self.D)*(1-r),size=self.n)\n",
    "        return samples.reshape((-1,self.D)) # [number of theta samples (normally 1) x self.n] x self.D\n",
    "\n",
    "    # B. correlation between latent\n",
    "    def _ss_corr(self, Z):\n",
    "        V = np.mat(Z).T * np.mat(Z) / Z.shape[0]\n",
    "        (d,d) = V.shape\n",
    "        upper_tri_elements = V[np.triu_indices(d, k=1)]\n",
    "        stat = np.array(upper_tri_elements)\n",
    "        return stat\n",
    "    \n",
    "    def statistics(self, data, theta=None):\n",
    "        if self.stat == 'raw':\n",
    "            # (correlation) as summary statistics (all margianls are N(0,1) here, don't matter)\n",
    "            stat = self._ss_corr(data)\n",
    "            return stat\n",
    "        else:\n",
    "            raise NotImplementedError('No ground truth statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = 'results/Gauss'\n",
    "\n",
    "problem = Gauss_Problem()\n",
    "theta = problem.sample_from_prior(size=20) # sample some thetas\n",
    "problem.data_obs = problem.simulator(theta) # generate 'true' observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sequential Neural Likelihood + \n",
    "hyperparams = ABC_algorithms.Hyperparams()\n",
    "hyperparams.save_dir = DIR\n",
    "hyperparams.device = 'cuda:0'\n",
    "hyperparams.num_sim = 1000                        # number of simulations\n",
    "hyperparams.L = 5                                # number of learning rounds\n",
    "hyperparams.hidden_ratio = 0.1                   # dimensionality of S(x)\n",
    "hyperparams.type = 'plain'                       # the network architecture of S(x), use CNN here\n",
    "hyperparams.estimator = 'DV'                    # MI estimator; JSD or DC, see the paper\n",
    "hyperparams.nde = 'MAF'                          # nde; MAF (D>1) or MDN (D=1)\n",
    "\n",
    "snl2_abc = SNL2ABC.SNL2_ABC(problem, discrepancy=discrepancy.eculidean_dist, hyperparams=hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "# of cpus =  4\n",
      "[ABC] sub-process start![ABC] sub-process start![ABC] sub-process start![ABC] sub-process start!\n",
      "\n",
      "\n",
      "\n",
      "[sampling] finished sampling  10\n",
      "[sampling] finished sampling  20\n",
      "[sampling] finished sampling  30\n",
      "[sampling] finished sampling  40\n",
      "\n",
      " > fitting encoder\n",
      "summary statistic dim = 1 original dim = 10\n",
      "architecture [10, 100, 100, 1]\n",
      "validation size= 0.8\n",
      "finished: t= 0 loss= 4.195095971226692e-05 loss val= -1.706508919596672e-05 time= 0.06907486915588379\n",
      "finished: t= 50 loss= -0.01616152562201023 loss val= -0.01970156468451023 time= 0.054346561431884766\n",
      "finished: t= 100 loss= -0.07106854766607285 loss val= -0.08608989417552948 time= 0.05495452880859375\n",
      "finished: t= 150 loss= -0.2636827230453491 loss val= -0.30058664083480835 time= 0.057027339935302734\n",
      "finished: t= 200 loss= -0.5412391424179077 loss val= -0.563347339630127 time= 0.05741763114929199\n",
      "finished: t= 250 loss= -0.7460415959358215 loss val= -0.7249103784561157 time= 0.055783748626708984\n",
      "finished: t= 300 loss= -0.9126104712486267 loss val= -0.8768243789672852 time= 0.05532336235046387\n",
      "finished: t= 350 loss= -1.0637843608856201 loss val= -1.0019527673721313 time= 0.0544278621673584\n",
      "finished: t= 400 loss= -1.160660982131958 loss val= -1.0912724733352661 time= 0.054863691329956055\n",
      "finished: t= 450 loss= -1.2424559593200684 loss val= -1.1653797626495361 time= 0.05413627624511719\n",
      "finished: t= 500 loss= -1.2952637672424316 loss val= -1.2278186082839966 time= 0.054708003997802734\n",
      "finished: t= 550 loss= -1.358999490737915 loss val= -1.2197165489196777 time= 0.054634809494018555\n",
      "finished: t= 600 loss= -1.3976860046386719 loss val= -1.2561527490615845 time= 0.05502820014953613\n",
      "finished: t= 650 loss= -1.4237780570983887 loss val= -1.2810945510864258 time= 0.0551908016204834\n",
      "finished: t= 700 loss= -1.4571491479873657 loss val= -1.2931734323501587 time= 0.05453658103942871\n",
      "finished: t= 750 loss= -1.4563360214233398 loss val= -1.2800804376602173 time= 0.054465532302856445\n",
      "finished: t= 800 loss= -1.4681222438812256 loss val= -1.267747163772583 time= 0.05864691734313965\n",
      "finished: t= 850 loss= -1.4721221923828125 loss val= -1.2891998291015625 time= 0.07556796073913574\n",
      "finished: t= 900 loss= -1.4730758666992188 loss val= -1.3181054592132568 time= 0.06061387062072754\n",
      "finished: t= 950 loss= -1.4919732809066772 loss val= -1.2772321701049805 time= 0.0568995475769043\n",
      "finished: t= 1000 loss= -1.4833300113677979 loss val= -1.2536180019378662 time= 0.05758833885192871\n",
      "best val loss= -1.3235259056091309\n",
      "\n",
      " > fitting nde\n",
      "all_stats.size() torch.Size([200, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ZeroDivisionError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-b6443f04028a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msnl2_abc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neural-approx-ss-lfi/algorithms/SNL2ABC.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_nde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn_proposal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_proposal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/algorithms/SNL2ABC.py\u001b[0m in \u001b[0;36mfit_nde\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all_stats.size()'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nde'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnde\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MAF'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cond_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnde\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MDN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMDN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMDN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/MAF.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, n_blocks, n_inputs, n_hidden, n_cond_inputs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_cond_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_cond_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mMADE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cond_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/MAF.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_inputs, num_hidden, num_cond_inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cond_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMADE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mhidden_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neural-approx-ss-lfi/nn/MAF.py\u001b[0m in \u001b[0;36mget_mask\u001b[0;34m(self, n_in, n_out, d, mask_type)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0min_degrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mout_degrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_degrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0min_degrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: ZeroDivisionError"
     ]
    }
   ],
   "source": [
    "snl2_abc.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = snl2_abc.problem.sample_from_prior(size=20000)\n",
    "# net = snl2_abc.nde_net\n",
    "# y_obs, theta = snl2_abc.convert_stat(snl2_abc.whiten(snl2_abc.y_obs)), theta\n",
    "# # y_obs = np.repeat(y_obs,400,axis=0)\n",
    "# print(y_obs.shape)\n",
    "# y_obs, theta = torch.tensor(y_obs).float(), torch.tensor(theta).float().view(1, -1)\n",
    "# log_probs = net.log_probs(inputs=y_obs, cond_inputs=theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.,  28.,  59., 155., 211., 228., 182.,  88.,  31.,  11.]),\n",
       " array([0.23878428, 0.29068191, 0.34257953, 0.39447716, 0.44637478,\n",
       "        0.4982724 , 0.55017003, 0.60206765, 0.65396528, 0.7058629 ,\n",
       "        0.75776052]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe52c2c2710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let us check that the prior did not collapse \n",
    "theta = np.empty(1000)\n",
    "for i in range(len(theta)): \n",
    "    theta[i] = snl2_abc.prior()\n",
    "plt.xlim([0,1])\n",
    "plt.hist(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7814, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate MI using all generated subsamples\n",
    "all_stats = torch.tensor(np.vstack(snl2_abc.all_stats[0:snl2_abc.l+1])).float()\n",
    "all_samples = torch.tensor(np.vstack(snl2_abc.all_samples[0:snl2_abc.l+1])).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.MI(all_stats,all_samples,n=100) # n here is the number of shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4016, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate MI using the last generated subsamples\n",
    "all_stats = torch.tensor(np.vstack(snl2_abc.all_stats[snl2_abc.l:snl2_abc.l+1])).float()\n",
    "all_samples = torch.tensor(np.vstack(snl2_abc.all_samples[snl2_abc.l:snl2_abc.l+1])).float()\n",
    "print(all_samples.shape)\n",
    "snl2_abc.vae_net.MI(all_stats,all_samples,n=100) # n here is the number of shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see Fig.4A in PLoS CB paper for correct answers. Should be roughly 1 bit for 10 dims (D), 0.7 dim for 5 dims\n",
    "# so far looks alright! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
